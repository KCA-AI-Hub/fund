from flask import Flask, render_template, request, jsonify, session
from openai import OpenAI
from dotenv import load_dotenv
import os
import uuid
from datetime import datetime
import logging
from logging.handlers import RotatingFileHandler
import json
import traceback
import requests
import pandas as pd
import re
import database  # SQLite law search functions

# Load environment variables
load_dotenv()

# Configure logging
def setup_logging(app):
    """Configure logging for both file and console output"""
    # Create logs directory if it doesn't exist
    if not os.path.exists('logs'):
        os.makedirs('logs')
    
    # Set up log format
    log_format = logging.Formatter(
        '%(asctime)s [%(levelname)s] %(name)s: %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # File handler with rotation
    file_handler = RotatingFileHandler(
        'logs/app.log',
        maxBytes=10 * 1024 * 1024,  # 10MB
        backupCount=10
    )
    file_handler.setFormatter(log_format)
    file_handler.setLevel(logging.INFO)
    
    # Console handler for development mode
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(log_format)
    console_handler.setLevel(logging.DEBUG if app.debug else logging.INFO)
    
    # Configure app logger
    app.logger.handlers.clear()  # Clear default handlers
    app.logger.addHandler(file_handler)
    app.logger.addHandler(console_handler)
    app.logger.setLevel(logging.DEBUG if app.debug else logging.INFO)
    
    # Configure werkzeug logger
    werkzeug_logger = logging.getLogger('werkzeug')
    werkzeug_logger.handlers.clear()
    werkzeug_logger.addHandler(file_handler)
    werkzeug_logger.addHandler(console_handler)
    werkzeug_logger.setLevel(logging.INFO)
    
    # Create separate logger for API calls
    api_logger = logging.getLogger('api_calls')
    api_file_handler = RotatingFileHandler(
        'logs/api_calls.log',
        maxBytes=10 * 1024 * 1024,  # 10MB
        backupCount=10
    )
    api_file_handler.setFormatter(log_format)
    api_logger.addHandler(api_file_handler)
    api_logger.addHandler(console_handler)
    api_logger.setLevel(logging.INFO)
    
    return api_logger

app = Flask(__name__)
app.config['SECRET_KEY'] = os.getenv('FLASK_SECRET_KEY', 'dev-secret-key')

# Setup logging
api_logger = setup_logging(app)

# Initialize OpenAI client
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
app.logger.info("OpenAI client initialized successfully")

# Dify Configuration
DIFY_API_URL = os.getenv('DIFY_API_URL', 'http://112.173.179.199:5001/v1')
DIFY_API_KEY = os.getenv('DIFY_API_KEY', '')
DIFY_DATASET_ID = os.getenv('DIFY_DATASET_ID', '')
AI_MODE = os.getenv('AI_MODE', 'dify')  # 'dify' or 'openai'
FALLBACK_TO_OPENAI = os.getenv('FALLBACK_TO_OPENAI', 'True').lower() == 'true'

app.logger.info(f"AI Mode: {AI_MODE}")
app.logger.info(f"Dify API URL: {DIFY_API_URL}")
app.logger.info(f"Dify Dataset ID: {DIFY_DATASET_ID}")
app.logger.info(f"Fallback to OpenAI: {FALLBACK_TO_OPENAI}")

# Store chat sessions in memory (in production, use a database)
chat_sessions = {}

# ========================================
# [1ë‹¨ê³„] ë§ˆìŠ¤í„° íŠ¸ë¦¬ ë°ì´í„° ë¡œë“œ (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ)
# ========================================
LAW_MASTER_TREE = {}

def build_law_master_tree():
    """
    DBì—ì„œ ë²•ë ¹ ë°ì´í„°ë¥¼ ì½ì–´ 3ë‹¨ ê³„ì¸µí˜• ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    êµ¬ì¡°: { ì§€ì¹¨ëª…: { ì œNì¡°: { title: "ì¡°í•­ì œëª©", paragraphs: ["í•­1ë‚´ìš©", "í•­2ë‚´ìš©"] } } }

    [ìˆ˜ì •ì‚¬í•­]
    1. Get or Create íŒ¨í„´: ì¡°(Article) ì¤‘ë³µ ìƒì„± ë°©ì§€
    2. ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ í•­(Paragraph) ê´€ë¦¬: law_idë¥¼ Unique Keyë¡œ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µ ì œê±°
    3. Natural Sort: ì œ1ì¡°, ì œ2ì¡°, ... ì œ10ì¡° ìˆœì„œë¡œ ì •ë ¬
    """
    import sqlite3
    global LAW_MASTER_TREE

    def extract_article_number(article_key):
        """'ì œ123ì¡°' â†’ 123 ì¶”ì¶œ (Natural Sortìš©)"""
        match = re.search(r'ì œ(\d+)ì¡°', article_key)
        return int(match.group(1)) if match else float('inf')

    try:
        conn = sqlite3.connect('data/chatbot.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        # ëª¨ë“  ë²•ë ¹ ë°ì´í„° ì¡°íšŒ (ì •ë ¬ ì œê±° - Pythonì—ì„œ Natural Sort ì ìš©)
        cursor.execute('''
            SELECT sheet_name, article_num, article_title, paragraph_num, paragraph_content, full_text, law_id
            FROM laws
            WHERE sheet_name IS NOT NULL AND article_num IS NOT NULL
        ''')

        rows = cursor.fetchall()
        conn.close()

        # 1ë‹¨ê³„: ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ ê³„ì¸µ êµ¬ì¡° ìƒì„± (ì¤‘ë³µ ì œê±°)
        tree = {}
        for row in rows:
            sheet_name = row['sheet_name']
            article_num = row['article_num']
            article_title = row['article_title'] or ''
            paragraph_num = row['paragraph_num']
            paragraph_content = row['paragraph_content'] or row['full_text'] or ''
            law_id = row['law_id']

            # ì§€ì¹¨ (Get or Create)
            if sheet_name not in tree:
                tree[sheet_name] = {}

            # ì¡° (Get or Create) - ì´ë¯¸ ì¡´ì¬í•˜ë©´ ê¸°ì¡´ ê°ì²´ ì‚¬ìš©
            article_key = f"ì œ{article_num}ì¡°"
            if article_key not in tree[sheet_name]:
                tree[sheet_name][article_key] = {
                    'title': article_title,
                    'paragraphs': {}  # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€ê²½! (Unique Key ê¸°ë°˜ ì¤‘ë³µ ì œê±°)
                }

            # í•­ (Unique Keyë¡œ ì¤‘ë³µ ì œê±°)
            if paragraph_content:
                # law_idë¥¼ Unique Keyë¡œ ì‚¬ìš© (ë” ì•ˆì •ì )
                para_key = law_id or f"{paragraph_num}_{hash(paragraph_content)}"
                if para_key not in tree[sheet_name][article_key]['paragraphs']:
                    if paragraph_num:
                        try:
                            para_text = f"ì œ{int(float(paragraph_num))}í•­: {paragraph_content}"
                        except (ValueError, TypeError):
                            para_text = f"{paragraph_num}: {paragraph_content}"
                    else:
                        para_text = paragraph_content
                    tree[sheet_name][article_key]['paragraphs'][para_key] = para_text

        # 2ë‹¨ê³„: Natural Sort ì ìš© + ë”•ì…”ë„ˆë¦¬ â†’ ë¦¬ìŠ¤íŠ¸ ë³€í™˜
        sorted_tree = {}
        for sheet_name, articles in tree.items():
            # ì¡°í•­ ì •ë ¬ (ì œ1ì¡°, ì œ2ì¡°, ... ì œ10ì¡° ìˆœ)
            sorted_articles = sorted(articles.items(), key=lambda x: extract_article_number(x[0]))

            sorted_tree[sheet_name] = {}
            for article_key, article_data in sorted_articles:
                sorted_tree[sheet_name][article_key] = {
                    'title': article_data['title'],
                    'paragraphs': list(article_data['paragraphs'].values())  # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                }

        LAW_MASTER_TREE = sorted_tree
        print(f"[Server] ë§ˆìŠ¤í„° íŠ¸ë¦¬ ë¡œë“œ ì™„ë£Œ: {len(sorted_tree)}ê°œ ì§€ì¹¨, ì´ {sum(len(v) for v in sorted_tree.values())}ê°œ ì¡°í•­")

    except Exception as e:
        print(f"[Server] ë§ˆìŠ¤í„° íŠ¸ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        LAW_MASTER_TREE = {}

# ì„œë²„ ì‹œì‘ ì‹œ ë§ˆìŠ¤í„° íŠ¸ë¦¬ ë¡œë“œ
build_law_master_tree()

# Load FAQ policy mapping from faq_topic.xlsx
faq_policy_map = {}
faq_df_global = None  # FAQ ì „ì²´ ë°ì´í„° ë³´ê´€ (ì§ì ‘ ë§¤ì¹­ìš©)
FAQ_DIRECT_THRESHOLD = float(os.getenv('FAQ_DIRECT_THRESHOLD', '0.85'))  # FAQ ì§ì ‘ ì‚¬ìš© ì„ê³„ê°’

try:
    faq_file_path = os.path.join(os.path.dirname(__file__), 'data', 'faq_topic.xlsx')
    if os.path.exists(faq_file_path):
        faq_df_global = pd.read_excel(faq_file_path)  # ì „ì²´ ë°ì´í„°í”„ë ˆì„ ë³´ê´€
        faq_policy_map = dict(zip(faq_df_global['faq_id'], faq_df_global['policy_anchor']))
        app.logger.info(f"Loaded {len(faq_policy_map)} FAQ policy mappings from {faq_file_path}")
        app.logger.info(f"FAQ direct match threshold: {FAQ_DIRECT_THRESHOLD}")
    else:
        app.logger.warning(f"FAQ file not found: {faq_file_path}")
except Exception as e:
    app.logger.error(f"Failed to load FAQ policy mapping: {e}")
    app.logger.error(traceback.format_exc())

# Request/Response logging middleware
@app.before_request
def log_request_info():
    """Log information about incoming requests"""
    app.logger.debug('Request Headers: %s', dict(request.headers))
    app.logger.info('Request: %s %s', request.method, request.path)
    if request.method in ['POST', 'PUT', 'PATCH']:
        if request.is_json:
            # Don't log sensitive data
            body = request.get_json()
            if body:
                safe_body = {k: v if k != 'api_key' else '***' for k, v in body.items()}
                app.logger.debug('Request Body: %s', json.dumps(safe_body, ensure_ascii=False)[:500])

@app.after_request
def log_response_info(response):
    """Log information about outgoing responses"""
    app.logger.info('Response: %s %s - Status: %s', 
                    request.method, request.path, response.status)
    return response

@app.route('/')
def index():
    """Render the main chat interface"""
    app.logger.info('Main page accessed from IP: %s', request.remote_addr)
    return render_template('index.html')

def extract_keywords_from_question(question: str) -> list:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ì‹)
    í–¥í›„ NLP ê¸°ë°˜ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥
    """
    # ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸
    stopwords = ['ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì—', 'ë¡œ', 'ìœ¼ë¡œ', 'ì™€', 'ê³¼',
                 'ì—ì„œ', 'ê¹Œì§€', 'ë¶€í„°', 'í•˜ë‹¤', 'ë˜ë‹¤', 'ìˆë‹¤', 'ì—†ë‹¤', 'í•˜ëŠ”', 'ë˜ëŠ”',
                 'ì–´ë–»ê²Œ', 'ë¬´ì—‡', 'ì–¸ì œ', 'ì–´ë””', 'ì™œ', 'ëˆ„ê°€', 'ì–´ë–¤', 'ëª‡', 'ì–¼ë§ˆ',
                 'í•©ë‹ˆë‹¤', 'ì…ë‹ˆë‹¤', 'ìŠµë‹ˆë‹¤', 'ë‹ˆë‹¤', 'ìš”', 'í• ', 'ìˆ˜', 'ê²ƒ', 'ë“±']

    # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬
    import re
    words = re.sub(r'[^\w\s]', ' ', question).split()

    # ë¶ˆìš©ì–´ ì œê±° ë° 2ê¸€ì ì´ìƒë§Œ ì¶”ì¶œ
    keywords = [w for w in words if len(w) >= 2 and w not in stopwords]

    return keywords[:5]  # ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œ

def search_laws_by_keywords(keywords: list, limit: int = 5) -> list:
    """
    í‚¤ì›Œë“œ ê¸°ë°˜ SQLite ë²•ë ¹ ê²€ìƒ‰ (ì¤‘ë³µ ì œê±° í¬í•¨)
    - sheet_name + article_num ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
    """
    if not keywords:
        return []

    all_results = []
    seen_keys = set()  # ì¤‘ë³µ ì²´í¬ìš© (sheet_name + article_num ì¡°í•©)
    total_raw_count = 0  # ì¤‘ë³µ ì œê±° ì „ ì´ ê°œìˆ˜

    for keyword in keywords:
        laws = database.search_laws(keyword, limit=3)
        total_raw_count += len(laws)  # ì›ë³¸ ê°œìˆ˜ ëˆ„ì 
        for law in laws:
            sheet_name = law.get('sheet_name') or ''
            article_num = law.get('article_num') or ''

            # ê³ ìœ  í‚¤: sheet_name + article_num ì¡°í•© (law_id ë¬´ì‹œ)
            unique_key = f"{sheet_name}_{article_num}"

            # ì¤‘ë³µ ì²´í¬
            if unique_key in seen_keys:
                continue

            seen_keys.add(unique_key)
            all_results.append({
                'law_id': law.get('law_id'),
                'title': law.get('article_title') or law.get('law_title') or 'ì œëª© ì—†ìŒ',
                'content': law.get('full_text') or law.get('paragraph_content') or '',
                'sheet_name': sheet_name,
                'article_num': article_num,
                'source': 'SQLite DB',
                'matched_keyword': keyword
            })

    # ì¤‘ë³µ ì œê±° ë¡œê·¸ ì¶œë ¥
    print(f"[Dedup] ì¤‘ë³µ ì œê±° ì „: {total_raw_count}ê°œ, í›„: {len(all_results)}ê°œ")

    return all_results[:limit]

@app.route('/api/chat', methods=['POST'])
def chat():
    """Handle chat messages and generate responses"""
    session_id = None
    try:
        data = request.get_json()
        user_message = data.get('message', '')
        session_id = data.get('session_id', str(uuid.uuid4()))
        prompt_template = data.get('prompt_template', None)  # ì„ íƒì  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

        app.logger.info(f'Chat request from session {session_id}: {user_message[:100]}...')
        api_logger.info(f'Session {session_id} - User message: {user_message}')

        # Initialize session if new
        if session_id not in chat_sessions:
            chat_sessions[session_id] = {
                'messages': [],
                'created_at': datetime.now()
            }

        # Add user message to session
        chat_sessions[session_id]['messages'].append({
            'role': 'user',
            'content': user_message
        })

        assistant_message = None
        retrieved_docs = []
        matched_faq_id = None
        related_laws = []

        # ===== [Action A] í‚¤ì›Œë“œ ì¶”ì¶œ & SQLite ë²•ë ¹ ê²€ìƒ‰ (ì¦‰ì‹œ ì‹¤í–‰) =====
        app.logger.info('[Action A] Extracting keywords and searching SQLite DB')
        keywords = extract_keywords_from_question(user_message)
        app.logger.info(f'Extracted keywords: {keywords}')

        sqlite_laws = search_laws_by_keywords(keywords, limit=5)
        app.logger.info(f'Found {len(sqlite_laws)} laws from SQLite')

        # SQLite ê²€ìƒ‰ ê²°ê³¼ë¥¼ related_lawsì— ì¦‰ì‹œ ì €ì¥
        for law in sqlite_laws:
            related_laws.append({
                'title': f"{law['sheet_name']} - {law['title']}",
                'content': law['content'][:300] + ('...' if len(law['content']) > 300 else ''),
                'article_num': law['article_num'],
                'source': 'SQLite DB',
                'matched_keyword': law.get('matched_keyword', '')
            })

        # ===== [Action B] Dify API í˜¸ì¶œ (Hybrid RAG Mode) =====
        if AI_MODE == 'dify':
            try:
                app.logger.info('Using Hybrid RAG mode (Dify FAQ + Local Policy Mapping)')

                # STEP 1: Search FAQ in Dify Knowledge
                app.logger.info('Step 1: Searching FAQ in Dify Knowledge')
                faq_result = call_dify_knowledge(user_message, top_k=3)

                if faq_result['success'] and faq_result['records']:
                    retrieved_docs = faq_result['records']
                    app.logger.info(f'Retrieved {len(retrieved_docs)} FAQ records')

                    # STEP 2: Extract faq_id and score from best match
                    app.logger.info('Step 2: Extracting faq_id from best match')
                    best_faq = retrieved_docs[0]
                    faq_score = best_faq.get('score', 0)
                    faq_id = extract_faq_id_from_content(best_faq)

                    app.logger.info(f'Best FAQ score: {faq_score}, threshold: {FAQ_DIRECT_THRESHOLD}')

                    if faq_id:
                        app.logger.info(f'Extracted faq_id: {faq_id}')
                        matched_faq_id = faq_id

                        # â˜…â˜…â˜… FAQ ë†’ì€ ë§¤ì¹­ ì²´í¬ (score >= threshold) â˜…â˜…â˜…
                        if faq_score >= FAQ_DIRECT_THRESHOLD:
                            app.logger.info(f'[FAQ High Match] Score {faq_score} >= {FAQ_DIRECT_THRESHOLD}')

                            # FAQ ë‹µë³€ ì¡°íšŒ
                            faq_data = get_faq_direct_answer(faq_id)

                            if faq_data and faq_data.get('answer_text'):
                                # â˜… policy_anchor ê¸°ë°˜ ë²•ë ¹ë§Œ ì‚¬ìš© (í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì´ˆê¸°í™”)
                                related_laws = []
                                policy_docs = []

                                if faq_data.get('policy_anchor'):
                                    policy_anchors = [p.strip() for p in faq_data['policy_anchor'].split(';')]
                                    for anchor in policy_anchors:
                                        if anchor:
                                            # â˜… ìƒˆë¡œìš´ policy_anchor ì „ìš© ê²€ìƒ‰ í•¨ìˆ˜ ì‚¬ìš©
                                            laws = database.search_laws_by_policy_anchor(anchor, limit=1)
                                            for law in laws:
                                                related_laws.append({
                                                    'title': f"{law.get('sheet_name', '')} - {law.get('article_title', '')}",
                                                    'content': (law.get('full_text') or law.get('paragraph_content') or '')[:500],
                                                    'article_num': law.get('article_num', ''),
                                                    'sheet_name': law.get('sheet_name', ''),
                                                    'source': 'FAQ High Match',
                                                    'matched_keyword': anchor
                                                })
                                                policy_docs.append({
                                                    'segment': {
                                                        'content': law.get('full_text') or law.get('paragraph_content') or '',
                                                        'document': {'name': law.get('sheet_name', '')}
                                                    },
                                                    'score': 0.9
                                                })

                                # â˜… GPTë¡œ ë‹µë³€ ìƒì„± (FAQ + ë²•ë ¹ ì»¨í…ìŠ¤íŠ¸) - í¬ë§·ì— ë§ê²Œ
                                app.logger.info('[FAQ High Match] Generating answer with GPT context')
                                assistant_message = generate_answer_with_context(
                                    user_message,
                                    retrieved_docs,  # Difyì—ì„œ ë°›ì€ FAQ ë ˆì½”ë“œ
                                    policy_docs if policy_docs else None
                                )

                                app.logger.info(f'[FAQ High Match] Completed - found {len(related_laws)} laws from policy_anchor')

                                # ì´í›„ ì •ìƒ íë¦„ ë”°ë¼ê° (suggested_answer ë“±)

                            else:
                                app.logger.warning(f'[FAQ High Match] Failed to get FAQ data, falling back to normal flow')

                        # â˜…â˜…â˜… ê¸°ì¡´ ë¡œì§: scoreê°€ ë‚®ìœ¼ë©´ GPT ìƒì„± â˜…â˜…â˜…
                        app.logger.info(f'Using GPT generation (score {faq_score} < {FAQ_DIRECT_THRESHOLD} or FAQ data unavailable)')

                        # STEP 3: Get policy_anchor from local mapping
                        app.logger.info('Step 3: Getting policy_anchor from local mapping')
                        policy_anchor = get_policy_anchor(faq_id)

                        if policy_anchor:
                            app.logger.info(f'Mapped policy_anchor: {policy_anchor[:100]}...')

                            # STEP 4: Search policy documents in SQLite DB
                            app.logger.info('Step 4: Searching policy documents in SQLite DB')
                            policy_docs = []
                            policy_anchors = [p.strip() for p in policy_anchor.split(';')]

                            for idx, anchor in enumerate(policy_anchors[:2], 1):  # Max 2 anchors
                                app.logger.debug(f'Searching laws in SQLite {idx}: {anchor[:50]}...')
                                laws = database.search_laws_by_policy_anchor(anchor, limit=2)

                                # Convert SQLite format to Dify-compatible format
                                for law in laws:
                                    policy_docs.append({
                                        'segment': {
                                            'content': law['paragraph_content'] or law['full_text'],
                                            'document': {'name': law['sheet_name']}
                                        },
                                        'score': 0.85  # SQLite doesn't provide scores
                                    })
                                    app.logger.debug(f'Found law: {law["article_title"] or law["law_title"]}')

                            app.logger.info(f'Total policy docs retrieved from SQLite: {len(policy_docs)}')

                            # STEP 5: Generate answer with FAQ + Policy context
                            app.logger.info('Step 5: Generating answer with FAQ + Policy context')
                            assistant_message = generate_answer_with_context(
                                user_message,
                                retrieved_docs,
                                policy_docs
                            )

                            # STEP 6: Build related_laws from policy_anchor (NOT LLM generated!)
                            related_laws = []
                            for anchor in policy_anchors:
                                related_laws.append({
                                    'title': anchor.strip(),
                                    'source': 'FAQ Database',
                                    'faq_id': faq_id
                                })

                            app.logger.info(f'Hybrid RAG completed successfully for faq_id: {faq_id}')

                        else:
                            # No policy_anchor found, use FAQ only
                            app.logger.warning(f'No policy_anchor found for {faq_id}, using FAQ only')
                            assistant_message = generate_answer_with_context(
                                user_message,
                                retrieved_docs,
                                None
                            )

                    else:
                        # Could not extract faq_id, use basic RAG
                        app.logger.warning('Could not extract faq_id, using basic Dify RAG')
                        assistant_message = generate_answer_with_dify_rag(
                            user_message,
                            retrieved_docs,
                            prompt_template
                        )

                    app.logger.info(f'Answer generated for session {session_id}')

                # Fallback: Dify ì‹¤íŒ¨ ì‹œ ë¡œì»¬ FAQ ê²€ìƒ‰ ì‹œë„
                elif FALLBACK_TO_OPENAI:
                    app.logger.warning('Dify FAQ search failed or no results, trying local FAQ search')

                    # â˜… ë¡œì»¬ FAQ ê²€ìƒ‰ ì‹œë„
                    local_faq_match = search_faq_local(user_message, threshold=0.5)

                    if local_faq_match and local_faq_match.get('score', 0) >= FAQ_DIRECT_THRESHOLD:
                        # ë¡œì»¬ FAQì—ì„œ ë†’ì€ ë§¤ì¹­ ë°œê²¬
                        faq_id = local_faq_match['faq_id']
                        faq_score = local_faq_match['score']
                        matched_faq_id = faq_id
                        app.logger.info(f'[Local FAQ Match] Score {faq_score:.2f} >= {FAQ_DIRECT_THRESHOLD}')

                        faq_data = get_faq_direct_answer(faq_id)

                        if faq_data and faq_data.get('answer_text'):
                            # policy_anchor ê¸°ë°˜ ë²•ë ¹ ê²€ìƒ‰
                            related_laws = []  # í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì´ˆê¸°í™”
                            policy_docs = []

                            if faq_data.get('policy_anchor'):
                                policy_anchors = [p.strip() for p in faq_data['policy_anchor'].split(';')]
                                for anchor in policy_anchors:
                                    if anchor:
                                        laws = database.search_laws_by_policy_anchor(anchor, limit=2)
                                        for law in laws:
                                            related_laws.append({
                                                'title': f"{law.get('sheet_name', '')} - {law.get('article_title', '')}",
                                                'content': (law.get('full_text') or law.get('paragraph_content') or '')[:500],
                                                'article_num': law.get('article_num', ''),
                                                'sheet_name': law.get('sheet_name', ''),
                                                'source': 'Local FAQ Match',
                                                'matched_keyword': anchor
                                            })
                                            # GPT ì»¨í…ìŠ¤íŠ¸ìš© policy_docs
                                            policy_docs.append({
                                                'segment': {
                                                    'content': law.get('full_text') or law.get('paragraph_content') or '',
                                                    'document': {'name': law.get('sheet_name', '')}
                                                },
                                                'score': 0.9
                                            })

                            # FAQë¥¼ Dify í¬ë§·ìœ¼ë¡œ ë³€í™˜í•´ì„œ GPTì— ì „ë‹¬
                            faq_records = [{
                                'segment': {
                                    'content': f'faq_id":"{faq_id}";"question":"{faq_data["question"]}";"answer_text":"{faq_data["answer_text"]}"',
                                    'document': {'name': 'Local FAQ'}
                                },
                                'score': faq_score
                            }]

                            # â˜… GPTë¡œ ë‹µë³€ ìƒì„± (FAQ + ë²•ë ¹ ì»¨í…ìŠ¤íŠ¸)
                            app.logger.info('[Local FAQ Match] Generating answer with GPT context')
                            assistant_message = generate_answer_with_context(
                                user_message,
                                faq_records,
                                policy_docs if policy_docs else None
                            )

                            app.logger.info(f'[Local FAQ Match] Completed - found {len(related_laws)} laws')

                            # ì´í›„ ë¡œì§ì€ ì •ìƒ íë¦„ ë”°ë¼ê° (suggested_answer ìƒì„± ë“±)

                    else:
                        # ë¡œì»¬ FAQë„ ë§¤ì¹­ ì•ˆ ë˜ë©´ OpenAI í´ë°±
                        app.logger.warning('Local FAQ search also failed, falling back to OpenAI')
                        assistant_message = generate_openai_response(session_id, user_message)
                else:
                    # No fallback, return error
                    raise Exception('Dify FAQ search failed and fallback is disabled')

            except Exception as e:
                app.logger.error(f'Error in Hybrid RAG mode: {str(e)}')
                app.logger.error(traceback.format_exc())
                if FALLBACK_TO_OPENAI:
                    app.logger.warning('Falling back to OpenAI due to error')
                    assistant_message = generate_openai_response(session_id, user_message)
                else:
                    raise

        # ===== OpenAI Direct Mode =====
        else:
            app.logger.info('Using OpenAI direct mode')
            assistant_message = generate_openai_response(session_id, user_message)

        # Add assistant message to session
        chat_sessions[session_id]['messages'].append({
            'role': 'assistant',
            'content': assistant_message
        })

        # Generate suggested answer
        suggested_answer = generate_suggested_answer(
            user_message,
            assistant_message,
            matched_faq_id=matched_faq_id,
            related_laws=related_laws
        )

        # related_lawsëŠ” ì´ë¯¸ [Action A]ì—ì„œ SQLite ê²€ìƒ‰ ê²°ê³¼ë¡œ ì±„ì›Œì ¸ ìˆìŒ
        # Difyì—ì„œ ì¶”ê°€ ë²•ë ¹ ì •ë³´ê°€ ìˆìœ¼ë©´ ë³‘í•©
        app.logger.info(f'[Final] Total related_laws from SQLite: {len(related_laws)}')

        app.logger.info(f'Successfully processed chat request for session {session_id}')

        # Build response with metadata
        response_data = {
            'success': True,
            'message': assistant_message,
            'suggested_answer': suggested_answer,
            'related_laws': related_laws,
            'session_id': session_id,
            'metadata': {
                'ai_mode': AI_MODE,
                'retrieval_count': len(retrieved_docs) if retrieved_docs else 0,
                'matched_faq_id': matched_faq_id,
                'extracted_keywords': keywords,
                'sqlite_laws_count': len(sqlite_laws)
            }
        }

        # Add retrieved documents info if available
        if retrieved_docs:
            response_data['metadata']['retrieved_docs'] = [
                {
                    'document_name': doc.get('segment', {}).get('document', {}).get('name', 'ì•Œ ìˆ˜ ì—†ìŒ'),
                    'score': doc.get('score', 0),
                    'content_preview': doc.get('segment', {}).get('content', '')[:100] + '...'
                }
                for doc in retrieved_docs
            ]

        return jsonify(response_data)

    except Exception as e:
        error_session = session_id if session_id else 'unknown'
        app.logger.error(f'Error in chat endpoint for session {error_session}: {str(e)}')
        app.logger.error(f'Traceback: {traceback.format_exc()}')
        return jsonify({
            'success': False,
            'error': str(e),
            'ai_mode': AI_MODE
        }), 500

def generate_openai_response(session_id, user_message):
    """Generate response using OpenAI directly (without RAG)"""
    app.logger.debug('Calling OpenAI API for session %s', session_id)
    start_time = datetime.now()

    # Prepare messages for OpenAI API
    messages = [
        {'role': 'system', 'content': '''ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ê³µë¬´ì›ì´ ë¯¼ì›ì¸ì˜ ë¬¸ì˜ì— ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•˜ê¸° ìœ„í•œ ê¸°ê¸ˆ ë¯¼ì›ì²˜ë¦¬ ì „ë¬¸ê°€ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¼ì£¼ì„¸ìš”:
1. í•­ìƒ ì •ì¤‘í•˜ê³  ê³µì†í•œ ì–´íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
2. ê´€ë ¨ ë²•ë ¹ì´ë‚˜ ê·œì •ì„ ì¸ìš©í•  ë•ŒëŠ” ì •í™•í•œ ì¡°í•­ì„ ëª…ì‹œí•˜ì„¸ìš”
3. í•„ìš”í•œ ì„œë¥˜ë‚˜ ì ˆì°¨ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì•ˆë‚´í•˜ì„¸ìš”
4. ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'''}
    ]
    messages.extend(chat_sessions[session_id]['messages'])

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.7,
        max_tokens=1000
    )

    elapsed_time = (datetime.now() - start_time).total_seconds()
    api_logger.info(f'OpenAI API call completed in {elapsed_time:.2f}s - Tokens used: {response.usage.total_tokens}')

    assistant_message = response.choices[0].message.content
    app.logger.info(f'Generated response for session {session_id}: {assistant_message[:100]}...')

    return assistant_message

def extract_laws_from_retrieved_docs(retrieved_docs):
    """Extract related laws from Dify retrieved documents"""
    related_laws = []

    for doc in retrieved_docs:
        segment = doc.get('segment', {})
        content = segment.get('content', '')
        document_name = segment.get('document', {}).get('name', 'ì•Œ ìˆ˜ ì—†ìŒ')
        score = doc.get('score', 0)

        related_laws.append({
            'title': document_name,
            'content': content[:300] + ('...' if len(content) > 300 else ''),
            'score': score,
            'source': 'Dify Knowledge'
        })

    return related_laws

def call_dify_knowledge(user_message, top_k=3):
    """
    Call Dify Knowledge API to retrieve relevant documents using RAG

    Args:
        user_message: User's query
        top_k: Number of top results to retrieve (default: 3)

    Returns:
        dict: Response containing retrieved documents and generated answer
    """
    try:
        app.logger.debug('Calling Dify Knowledge API')
        start_time = datetime.now()

        # Dify Knowledge Retrieve API endpoint
        url = f"{DIFY_API_URL}/datasets/{DIFY_DATASET_ID}/retrieve"

        headers = {
            'Authorization': f'Bearer {DIFY_API_KEY}',
            'Content-Type': 'application/json'
        }

        payload = {
            "query": user_message,
            "retrieval_model": {
                "search_method": "semantic_search",  # or "full_text_search", "hybrid_search"
                "reranking_enable": False,  # Reranking ë¹„í™œì„±í™” (OpenAI API ë¶ˆí•„ìš”)
                "top_k": top_k,
                "score_threshold_enabled": True,
                "score_threshold": 0.5
            }
        }

        app.logger.debug(f"Dify API Request URL: {url}")
        app.logger.debug(f"Dify API Request Payload: {json.dumps(payload, ensure_ascii=False)}")

        response = requests.post(url, headers=headers, json=payload, timeout=30)
        response.raise_for_status()

        result = response.json()
        elapsed_time = (datetime.now() - start_time).total_seconds()

        # Extract retrieved documents
        records = result.get('records', [])
        app.logger.info(f"Dify Knowledge API call completed in {elapsed_time:.2f}s - Retrieved {len(records)} documents")
        api_logger.info(f"Dify RAG retrieved {len(records)} documents for query: {user_message[:100]}")

        # Log retrieved documents
        for idx, record in enumerate(records):
            score = record.get('score', 0)
            segment = record.get('segment', {})
            content_preview = segment.get('content', '')[:100]
            app.logger.debug(f"Document {idx+1} - Score: {score:.3f} - Content: {content_preview}...")

        return {
            'success': True,
            'records': records,
            'query': user_message,
            'elapsed_time': elapsed_time
        }

    except requests.exceptions.Timeout:
        app.logger.error('Dify API request timeout')
        return {
            'success': False,
            'error': 'Dify API timeout',
            'records': []
        }
    except requests.exceptions.RequestException as e:
        app.logger.error(f'Dify API request failed: {str(e)}')
        app.logger.error(f'Response: {e.response.text if hasattr(e, "response") else "No response"}')
        return {
            'success': False,
            'error': str(e),
            'records': []
        }
    except Exception as e:
        app.logger.error(f'Unexpected error calling Dify API: {str(e)}')
        app.logger.error(f'Traceback: {traceback.format_exc()}')
        return {
            'success': False,
            'error': str(e),
            'records': []
        }

def extract_faq_id_from_content(record):
    """
    Extract faq_id from Dify search result

    Args:
        record: Single record from Dify API response

    Returns:
        str: faq_id (e.g., "FAQ-í˜‘ì•½ì²´ê²°-0002") or None
    """
    try:
        content = record.get('segment', {}).get('content', '')

        # Method 1: Regex search for faq_id in CSV format
        # Content format: faq_id":"FAQ-í˜‘ì•½ì²´ê²°-0002";"question":"..."
        match = re.search(r'faq_id":"(.+?)"', content)
        if match:
            faq_id = match.group(1)
            app.logger.debug(f"Extracted faq_id from content: {faq_id}")
            return faq_id

        # Method 2: Check document name
        doc_name = record.get('segment', {}).get('document', {}).get('name', '')
        if doc_name and doc_name.startswith('FAQ-') and doc_name.endswith('.md'):
            faq_id = doc_name[:-3]  # Remove .md extension
            app.logger.debug(f"Extracted faq_id from document name: {faq_id}")
            return faq_id

        app.logger.warning("Could not extract faq_id from record")
        return None

    except Exception as e:
        app.logger.error(f"Error extracting faq_id: {e}")
        return None

def get_policy_anchor(faq_id):
    """
    Get policy_anchor from local mapping table

    Args:
        faq_id: FAQ identifier (e.g., "FAQ-í˜‘ì•½ì²´ê²°-0002")

    Returns:
        str: policy_anchor or None
    """
    if not faq_id:
        return None

    policy_anchor = faq_policy_map.get(faq_id)

    if policy_anchor:
        app.logger.debug(f"Mapped {faq_id} -> {policy_anchor[:50]}...")
    else:
        app.logger.warning(f"No policy_anchor found for faq_id: {faq_id}")

    return policy_anchor

def get_faq_direct_answer(faq_id):
    """
    FAQ ë‹µë³€ì„ ì§ì ‘ ì¡°íšŒ (ë†’ì€ ìœ ì‚¬ë„ ë§¤ì¹­ ì‹œ GPT í˜¸ì¶œ ì—†ì´ ì‚¬ìš©)

    Args:
        faq_id: FAQ identifier (e.g., "FAQ-í˜‘ì•½ì²´ê²°-0002")

    Returns:
        dict: {'answer_text': str, 'policy_anchor': str, 'question': str} or None
    """
    global faq_df_global

    if faq_df_global is None or faq_id is None:
        return None

    try:
        row = faq_df_global[faq_df_global['faq_id'] == faq_id]
        if row.empty:
            app.logger.warning(f"FAQ not found for direct answer: {faq_id}")
            return None

        result = {
            'faq_id': faq_id,
            'answer_text': str(row['answer_text'].values[0]) if pd.notna(row['answer_text'].values[0]) else '',
            'policy_anchor': str(row['policy_anchor'].values[0]) if pd.notna(row['policy_anchor'].values[0]) else '',
            'question': str(row['question'].values[0]) if pd.notna(row['question'].values[0]) else ''
        }
        app.logger.info(f"[FAQ Direct] Retrieved answer for {faq_id}")
        return result

    except Exception as e:
        app.logger.error(f"Error getting FAQ direct answer: {e}")
        return None

def format_faq_as_html(faq_data, user_message):
    """
    FAQ ë‹µë³€ì„ HTML í¬ë§·ìœ¼ë¡œ ë³€í™˜ (suggested_answerìš©)

    Args:
        faq_data: get_faq_direct_answer()ì˜ ë°˜í™˜ê°’
        user_message: ì‚¬ìš©ì ì§ˆë¬¸

    Returns:
        str: HTML í¬ë§· ë‹µë³€
    """
    if not faq_data:
        return "<p>ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</p>"

    answer_text = faq_data.get('answer_text', '')

    # ì¤„ë°”ê¿ˆì„ <br>ë¡œ ë³€í™˜
    formatted_answer = answer_text.replace('\n', '<br>')

    return f"""
<div class="answer-section">
    <h4>ğŸ“Œ ë‹µë³€</h4>
    <p>{formatted_answer}</p>
</div>
<div class="answer-section">
    <h4>ğŸ’¡ ì°¸ê³ ì‚¬í•­</h4>
    <p>ê´€ë ¨ ë²•ë ¹ì€ ì˜¤ë¥¸ìª½ 'ê´€ë ¨ë²•ë ¹' íƒ­ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
</div>
"""

def search_faq_local(user_message, threshold=0.6):
    """
    ë¡œì»¬ faq_topic.xlsxì—ì„œ ìœ ì‚¬í•œ FAQ ê²€ìƒ‰ (Dify ì‹¤íŒ¨ ì‹œ í´ë°±ìš©)
    ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ê¸°ë°˜ ê²€ìƒ‰

    Args:
        user_message: ì‚¬ìš©ì ì§ˆë¬¸
        threshold: ë§¤ì¹­ ì„ê³„ê°’ (0~1)

    Returns:
        dict: {'faq_id': str, 'score': float, 'question': str} or None
    """
    global faq_df_global

    if faq_df_global is None:
        return None

    try:
        # ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        user_keywords = set(user_message.replace('?', '').replace('ï¼Ÿ', '').split())

        best_match = None
        best_score = 0

        for _, row in faq_df_global.iterrows():
            faq_question = str(row.get('question', ''))
            faq_keywords = set(faq_question.replace('?', '').replace('ï¼Ÿ', '').split())

            # Jaccard ìœ ì‚¬ë„ ê³„ì‚°
            if len(user_keywords | faq_keywords) > 0:
                score = len(user_keywords & faq_keywords) / len(user_keywords | faq_keywords)

                # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²½ìš° ë³´ë„ˆìŠ¤
                if user_message.strip() == faq_question.strip():
                    score = 1.0

                if score > best_score:
                    best_score = score
                    best_match = {
                        'faq_id': row.get('faq_id'),
                        'score': score,
                        'question': faq_question
                    }

        if best_match and best_score >= threshold:
            app.logger.info(f'[Local FAQ] Found match: {best_match["faq_id"]} (score: {best_score:.2f})')
            return best_match

        app.logger.info(f'[Local FAQ] No match found above threshold {threshold} (best: {best_score:.2f})')
        return None

    except Exception as e:
        app.logger.error(f'Error in local FAQ search: {e}')
        return None

def generate_answer_with_context(user_message, faq_records, policy_docs):
    """
    Generate answer using FAQ + Policy documents as context

    Args:
        user_message: User's question
        faq_records: FAQ records from Dify search
        policy_docs: Policy document records from Dify search (can be None/empty)

    Returns:
        str: Generated answer
    """
    try:
        # Build FAQ context
        faq_context = ""
        if faq_records:
            for idx, record in enumerate(faq_records[:2], 1):  # Top 2 FAQs
                content = record.get('segment', {}).get('content', '')
                # Extract question and answer from CSV format
                # Format: faq_id":"FAQ-...";"question":"ì§ˆë¬¸";"answer_text":"ë‹µë³€"
                question_match = re.search(r'question":"(.+?)"', content)
                answer_match = re.search(r'answer_text":"(.+?)"', content)

                if question_match and answer_match:
                    question = question_match.group(1)
                    answer = answer_match.group(1)
                    faq_context += f"\n[ì°¸ê³  FAQ {idx}]\nì§ˆë¬¸: {question}\në‹µë³€: {answer}\n"
                else:
                    # Fallback: use first 500 chars
                    faq_context += f"\n[ì°¸ê³  FAQ {idx}]\n{content[:500]}\n"

        # Build policy documents context
        policy_context = ""
        if policy_docs:
            for idx, doc in enumerate(policy_docs[:3], 1):  # Top 3 policy docs
                content = doc.get('segment', {}).get('content', '')
                policy_context += f"\n[ì°¸ê³  ë²•ë ¹ {idx}]\n{content[:500]}\n"

        # System prompt
        system_prompt = f"""ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ICT ê¸°ê¸ˆì‚¬ì—… ë¯¼ì›ì²˜ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ìë£Œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”:

{faq_context}

{policy_context}

ë‹µë³€ ì‹œ ì§€ì¹¨:
1. ìœ„ ì°¸ê³  ìë£Œì˜ ë‚´ìš©ì„ ì •í™•íˆ í™œìš©í•˜ì„¸ìš”
2. ë²•ë ¹ì´ë‚˜ ê·œì •ì„ ì¸ìš©í•  ë•ŒëŠ” ì •í™•í•œ ì¡°í•­ì„ ëª…ì‹œí•˜ì„¸ìš”
3. í•„ìš”í•œ ì„œë¥˜ë‚˜ ì ˆì°¨ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì•ˆë‚´í•˜ì„¸ìš”
4. ì°¸ê³  ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³ , ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•˜ë‹¤ê³  ì•ˆë‚´í•˜ì„¸ìš”
5. ì •ì¤‘í•˜ê³  ê³µì†í•œ ì–´íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”"""

        # Call OpenAI API
        start_time = datetime.now()
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_message}
            ],
            temperature=0.7,
            max_tokens=1000
        )

        elapsed_time = (datetime.now() - start_time).total_seconds()
        assistant_message = response.choices[0].message.content

        api_logger.info(f'Answer generated in {elapsed_time:.2f}s - Tokens: {response.usage.total_tokens}')
        app.logger.debug(f'Generated answer: {assistant_message[:100]}...')

        return assistant_message

    except Exception as e:
        app.logger.error(f'Error generating answer with context: {str(e)}')
        app.logger.error(traceback.format_exc())
        raise

def generate_answer_with_dify_rag(user_message, retrieved_docs, prompt_template=None):
    """
    Generate answer using OpenAI with Dify retrieved documents as context

    Args:
        user_message: User's query
        retrieved_docs: Documents retrieved from Dify Knowledge
        prompt_template: Optional custom prompt template

    Returns:
        str: Generated answer
    """
    try:
        app.logger.debug('Generating answer with RAG context')

        # Build context from retrieved documents
        context_parts = []
        for idx, record in enumerate(retrieved_docs):
            segment = record.get('segment', {})
            content = segment.get('content', '')
            dataset_name = record.get('dataset_name', 'ë¬¸ì„œ')
            document_name = segment.get('document', {}).get('name', 'ì•Œ ìˆ˜ ì—†ìŒ')
            score = record.get('score', 0)

            context_parts.append(f"""
[ì°¸ê³ ìë£Œ {idx+1}] (ê´€ë ¨ë„: {score:.2f})
ì¶œì²˜: {dataset_name} - {document_name}
ë‚´ìš©: {content}
""")

        context = "\n".join(context_parts)

        # Use custom prompt template or default
        if prompt_template:
            system_prompt = prompt_template
        else:
            system_prompt = f"""ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ê³µë¬´ì›ì´ ë¯¼ì›ì¸ì˜ ë¬¸ì˜ì— ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•˜ê¸° ìœ„í•œ ê¸°ê¸ˆ ë¯¼ì›ì²˜ë¦¬ ì „ë¬¸ê°€ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ë‹¤ìŒ ì°¸ê³ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

{context}

ë‹µë³€ ì‹œ ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¼ì£¼ì„¸ìš”:
1. í•­ìƒ ì •ì¤‘í•˜ê³  ê³µì†í•œ ì–´íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
2. ìœ„ ì°¸ê³ ìë£Œì˜ ë‚´ìš©ì„ ì •í™•íˆ ì¸ìš©í•˜ê³  í™œìš©í•˜ì„¸ìš”
3. ì°¸ê³ ìë£Œì— ëª…ì‹œëœ ë²•ë ¹ì´ë‚˜ ê·œì •ì´ ìˆë‹¤ë©´ ì •í™•í•œ ì¡°í•­ì„ ì¸ìš©í•˜ì„¸ìš”
4. í•„ìš”í•œ ì„œë¥˜ë‚˜ ì ˆì°¨ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì•ˆë‚´í•˜ì„¸ìš”
5. ì°¸ê³ ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³ , ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•˜ë‹¤ê³  ì•ˆë‚´í•˜ì„¸ìš”
6. ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”"""

        # Call OpenAI with RAG context
        start_time = datetime.now()

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_message}
            ],
            temperature=0.7,
            max_tokens=1000
        )

        elapsed_time = (datetime.now() - start_time).total_seconds()
        assistant_message = response.choices[0].message.content

        api_logger.info(f'RAG answer generated in {elapsed_time:.2f}s - Tokens: {response.usage.total_tokens}')

        return assistant_message

    except Exception as e:
        app.logger.error(f'Error generating RAG answer: {str(e)}')
        app.logger.error(f'Traceback: {traceback.format_exc()}')
        raise

def generate_suggested_answer(user_message, assistant_response, matched_faq_id=None, related_laws=None):
    """
    FAQ RAG ê¸°ë°˜ ë¯¼ì›ì²˜ë¦¬ ë‹µë³€ ìƒì„±

    Args:
        user_message: ì‚¬ìš©ì ì§ˆë¬¸
        assistant_response: ì±—ë´‡ ë‹µë³€ (FAQ RAG ê¸°ë°˜)
        matched_faq_id: ë§¤ì¹­ëœ FAQ ID (ì„ íƒ)
        related_laws: ê´€ë ¨ ë²•ë ¹ ë¦¬ìŠ¤íŠ¸ (ì„ íƒ, ë³„ë„ íƒ­ì— í‘œì‹œë¨)

    Returns:
        str: HTML í˜•ì‹ì˜ ë¯¼ì›ì²˜ë¦¬ ë‹µë³€
    """
    try:
        app.logger.debug(f'Generating suggested answer (FAQ ID: {matched_faq_id})')

        # ========================================
        # ğŸ“ ë‹µë³€ì§€ì¹¨ë€ (ë‚˜ì¤‘ì— ìˆ˜ì • ê°€ëŠ¥)
        # ========================================
        system_instruction = """ë‹¹ì‹ ì€ ICT ê¸°ê¸ˆì‚¬ì—…ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê¸°ê¸ˆê·œì • ì—…ë¬´ë¥¼ ë‹´ë‹¹í•˜ëŠ” ì§ì›ë“¤ì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤.
ì—…ë¬´ ì¡°ì–¸ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ë©°, ë¬¸ì˜ì²˜ ì•ˆë‚´ëŠ” í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

âš ï¸ ì¤‘ìš” ê·œì¹™:
- ê´€ë ¨ ë²•ë ¹ì€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš” (ë³„ë„ íƒ­ì— í‘œì‹œë¨)
- ë¬¸ì˜ì²˜(ì „í™”ë²ˆí˜¸, ì´ë©”ì¼)ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
- ê¹”ë”í•˜ê³  ë³´ê¸° ì¢‹ì€ HTMLë¡œ ì‘ì„±í•˜ì„¸ìš”

ğŸ“‹ HTML í¬ë§· ì§€ì¹¨:
- <div class="answer-section">ë¡œ ê° ì„¹ì…˜ì„ ê°ì‹¸ì„¸ìš”
- ì œëª©ì€ <h4>ë¥¼ ì‚¬ìš©í•˜ì„¸ìš” (ì˜ˆ: <h4>ğŸ“Œ í•µì‹¬ ë‹µë³€</h4>)
- ë³¸ë¬¸ì€ <p>ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- ëª©ë¡ì€ <ul><li>ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- ì ˆì°¨/ë‹¨ê³„ëŠ” <ol><li>ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- ê°•ì¡°ëŠ” <strong>ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ì—¬ë°±ì„ ìœ„í•´ <br> ëŒ€ì‹  ë³„ë„ <p> íƒœê·¸ ì‚¬ìš©

ğŸ“ ê¶Œì¥ ì„¹ì…˜ êµ¬ì¡° (ìƒí™©ì— ë§ê²Œ ì„ íƒ):
- ğŸ“Œ í•µì‹¬ ë‹µë³€ / ê°œìš”
- ğŸ“ ì‘ì„± ë‚´ìš© / í•„ìˆ˜ í•­ëª© / í¬í•¨ë˜ì–´ì•¼ í•  ë‚´ìš©
- ğŸ“‹ í•„ìš” ì„œë¥˜ / ì¤€ë¹„ ì„œë¥˜
- ğŸ”„ ì²˜ë¦¬ ì ˆì°¨ / ì§„í–‰ ê³¼ì •
- â° ì²˜ë¦¬ ê¸°ê°„ / ì†Œìš” ì‹œê°„
- âš ï¸ ì£¼ì˜ì‚¬í•­ / ìœ ì˜ì‚¬í•­
- ğŸ’¡ ì°¸ê³ ì‚¬í•­ / ì¶”ê°€ ì •ë³´ (ê´€ë ¨ ì²˜ë¦¬ì§€ì¹¨ í¬í•¨)

âœ… ì¢‹ì€ ì˜ˆì‹œ:
<div class="answer-section">
    <h4>ğŸ“Œ í•µì‹¬ ë‹µë³€</h4>
    <p>ì‚¬ì—…ë¹„ êµë¶€ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì ˆì°¨ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.</p>
</div>

<div class="answer-section">
    <h4>ğŸ“ í•„ìš” ì„œë¥˜</h4>
    <ul>
        <li><strong>í˜‘ì•½ì„œ:</strong> ì‚¬ì—… í˜‘ì•½ ì²´ê²° í›„ ì œì¶œ</li>
        <li><strong>ê³„ì¢Œ ì‚¬ë³¸:</strong> ì‚¬ì—…ì ëª…ì˜ ê³„ì¢Œ</li>
    </ul>
</div>

<div class="answer-section">
    <h4>ğŸ”„ ì²˜ë¦¬ ì ˆì°¨</h4>
    <ol>
        <li>í˜‘ì•½ ì²´ê²° ë° ì„œë¥˜ ì œì¶œ</li>
        <li>ì„œë¥˜ ê²€í†  (3-5ì¼ ì†Œìš”)</li>
        <li>êµë¶€ ìŠ¹ì¸ ë° ì…ê¸ˆ</li>
    </ol>
</div>

<div class="answer-section">
    <h4>ğŸ’¡ ì°¸ê³ ì‚¬í•­</h4>
    <p>ê´€ë ¨ ì²˜ë¦¬ì§€ì¹¨: ICT ê¸°ê¸ˆì‚¬ì—… ìš´ì˜ì§€ì¹¨ ì œXXì¡°ì— ë”°ë¼ ì²˜ë¦¬ë©ë‹ˆë‹¤.</p>
    <p>ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ê°€ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¸ì˜í•˜ì„¸ìš”.</p>
</div>
"""
        # ========================================

        prompt = f"""{system_instruction}

ì§ˆë¬¸: {user_message}
ì°¸ê³  ë‹µë³€: {assistant_response}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ì› ì—…ë¬´ ì¡°ì–¸ í˜•ì‹ì˜ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
ë°˜ë“œì‹œ ìœ„ì˜ HTML í¬ë§· ì§€ì¹¨ì„ ë”°ë¼ ê¹”ë”í•˜ê³  ë³´ê¸° ì¢‹ê²Œ êµ¬ì¡°í™”í•˜ì„¸ìš”.

âœ… í•„ìˆ˜ í¬í•¨ ì‚¬í•­:
- ì°¸ê³ ì‚¬í•­ ì„¹ì…˜ì— ê´€ë ¨ ì²˜ë¦¬ì§€ì¹¨(ìš´ì˜ì§€ì¹¨, ì‹œí–‰ì„¸ì¹™ ë“±)ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”
- ì²˜ë¦¬ì§€ì¹¨ì´ ì°¸ê³  ë‹µë³€ì— ìˆë‹¤ë©´ ë°˜ë“œì‹œ ëª…ì‹œí•˜ì„¸ìš”

âš ï¸ ì¤‘ìš”: HTML ì½”ë“œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ```html``` ê°™ì€ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ íƒœê·¸ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{'role': 'user', 'content': prompt}],
            temperature=0.3,  # ë‚®ì¶°ì„œ ë” ì¼ê´€ì„± ìˆëŠ” ë‹µë³€
            max_tokens=800
        )

        api_logger.info(f'Suggested answer generated - Tokens used: {response.usage.total_tokens}')

        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° (```html, ``` ë“±)
        answer = response.choices[0].message.content
        answer = answer.replace('```html', '').replace('```', '').strip()

        app.logger.debug(f'Generated answer length: {len(answer)}')

        return answer

    except Exception as e:
        app.logger.error(f'Error generating suggested answer: {str(e)}')
        app.logger.error(traceback.format_exc())
        return "<p>ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.</p>"

def generate_related_laws(user_message):
    """Generate related laws and regulations"""
    # Simplified version - in production, this would query a legal database
    common_laws = {
        'ê±´ì¶•': [
            {
                'title': 'ê±´ì¶•ë²•',
                'content': 'ì œ11ì¡° (ê±´ì¶•í—ˆê°€) ê±´ì¶•ë¬¼ì„ ê±´ì¶•í•˜ê±°ë‚˜ ëŒ€ìˆ˜ì„ í•˜ë ¤ëŠ” ìëŠ” íŠ¹ë³„ìì¹˜ì‹œì¥ã†íŠ¹ë³„ìì¹˜ë„ì§€ì‚¬ ë˜ëŠ” ì‹œì¥ã†êµ°ìˆ˜ã†êµ¬ì²­ì¥ì˜ í—ˆê°€ë¥¼ ë°›ì•„ì•¼ í•œë‹¤.'
            },
            {
                'title': 'ê±´ì¶•ë²• ì‹œí–‰ë ¹',
                'content': 'ì œ6ì¡° (ì ìš©ì˜ ì™„í™”) ê±´ì¶•ë¬¼ì˜ ëŒ€ì§€ê°€ ì§€ì—­ã†ì§€êµ¬ ë˜ëŠ” êµ¬ì—­ì— ê±¸ì¹˜ëŠ” ê²½ìš° ê·¸ ê±´ì¶•ë¬¼ê³¼ ëŒ€ì§€ì˜ ì „ë¶€ì— ëŒ€í•˜ì—¬ ëŒ€ì§€ì˜ ê³¼ë°˜ì´ ì†í•˜ëŠ” ì§€ì—­ã†ì§€êµ¬ ë˜ëŠ” êµ¬ì—­ ì•ˆì˜ ê±´ì¶•ë¬¼ ë° ëŒ€ì§€ì— ê´€í•œ ê·œì •ì„ ì ìš©í•œë‹¤.'
            }
        ],
        'ë„ë¡œ': [
            {
                'title': 'ë„ë¡œë²•',
                'content': 'ì œ61ì¡° (ë„ë¡œì ìš©í—ˆê°€) ë„ë¡œë¥¼ ì ìš©í•˜ë ¤ëŠ” ìëŠ” ë„ë¡œê´€ë¦¬ì²­ì˜ í—ˆê°€ë¥¼ ë°›ì•„ì•¼ í•œë‹¤.'
            }
        ],
        'í™˜ê²½': [
            {
                'title': 'í™˜ê²½ì •ì±…ê¸°ë³¸ë²•',
                'content': 'ì œ3ì¡° (ê¸°ë³¸ì´ë…) í™˜ê²½ì˜ ì§ˆì ì¸ í–¥ìƒê³¼ ê·¸ ë³´ì „ì„ í†µí•œ ì¾Œì í•œ í™˜ê²½ì˜ ì¡°ì„± ë° ì´ë¥¼ í†µí•œ ì¸ê°„ê³¼ í™˜ê²½ê°„ì˜ ì¡°í™”ì™€ ê· í˜•ì˜ ìœ ì§€ëŠ” êµ­ë¯¼ì˜ ê±´ê°•ê³¼ ë¬¸í™”ì ì¸ ìƒí™œì˜ í–¥ìœ  ë° êµ­í† ì˜ ë³´ì „ê³¼ í•­êµ¬ì ì¸ êµ­ê°€ë°œì „ì— í•„ìˆ˜ë¶ˆê°€ê²°í•œ ìš”ì†Œì„ì„ ì¸ì‹í•˜ê³ ...'
            }
        ]
    }
    
    # Simple keyword matching
    for keyword, laws in common_laws.items():
        if keyword in user_message:
            return laws
    
    # Default laws
    return [
        {
            'title': 'ë¯¼ì› ì²˜ë¦¬ì— ê´€í•œ ë²•ë¥ ',
            'content': 'ì œ9ì¡° (ë¯¼ì›ì˜ ì²˜ë¦¬ê¸°ê°„) í–‰ì •ê¸°ê´€ì˜ ì¥ì€ ë¯¼ì›ì˜ ì²˜ë¦¬ê¸°ê°„ì„ ì¢…ë¥˜ë³„ë¡œ ë¯¸ë¦¬ ì •í•˜ì—¬ ë¯¼ì›ì¸ì´ ì´ë¥¼ ì•Œ ìˆ˜ ìˆë„ë¡ ê²Œì‹œí•˜ê±°ë‚˜ ë¯¼ì›í¸ëŒì— ìˆ˜ë¡í•˜ëŠ” ë“±ì˜ ë°©ë²•ìœ¼ë¡œ ê³µí‘œí•˜ì—¬ì•¼ í•œë‹¤.'
        },
        {
            'title': 'í–‰ì •ì ˆì°¨ë²•',
            'content': 'ì œ17ì¡° (ì²˜ë¶„ì˜ ì‹ ì²­) í–‰ì •ì²­ì— ì²˜ë¶„ì„ êµ¬í•˜ëŠ” ì‹ ì²­ì€ ë¬¸ì„œë¡œ í•˜ì—¬ì•¼ í•œë‹¤. ë‹¤ë§Œ, ë‹¤ë¥¸ ë²•ë ¹ë“±ì— íŠ¹ë³„í•œ ê·œì •ì´ ìˆëŠ” ê²½ìš°ì™€ í–‰ì •ì²­ì´ ë¯¸ë¦¬ ë‹¤ë¥¸ ë°©ë²•ì„ ì •í•˜ì—¬ ê³µì‹œí•œ ê²½ìš°ì—ëŠ” ê·¸ëŸ¬í•˜ì§€ ì•„ë‹ˆí•˜ë‹¤.'
        }
    ]

# ========================================
# ê´€ë ¨ ë²•ë ¹ API ì—”ë“œí¬ì¸íŠ¸
# ========================================

@app.route('/api/laws/master-tree', methods=['GET'])
def get_law_master_tree():
    """
    [2ë‹¨ê³„] ë§ˆìŠ¤í„° íŠ¸ë¦¬ ë°ì´í„° ë°˜í™˜
    ì„œë²„ ì‹œì‘ ì‹œ ë¡œë“œí•œ ì „ì—­ ë³€ìˆ˜ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜ (DB ì‹¤ì‹œê°„ ì¡°íšŒ X)
    """
    try:
        app.logger.info(f'Master tree requested: {len(LAW_MASTER_TREE)} sheets')
        return jsonify({
            'success': True,
            'data': LAW_MASTER_TREE,
            'sheet_count': len(LAW_MASTER_TREE),
            'article_count': sum(len(v) for v in LAW_MASTER_TREE.values())
        })
    except Exception as e:
        app.logger.error(f'Error getting master tree: {str(e)}')
        return jsonify({'success': False, 'error': str(e), 'data': {}}), 500

@app.route('/api/laws/sheets', methods=['GET'])
def get_sheets():
    """Sheet ëª©ë¡ ì¡°íšŒ (ì§€ì¹¨ ëª©ë¡)"""
    try:
        sheets = database.get_sheet_list()
        app.logger.info(f'Retrieved {len(sheets)} sheets')
        return jsonify({'sheets': sheets})
    except Exception as e:
        app.logger.error(f'Error getting sheets: {str(e)}')
        return jsonify({'error': str(e), 'sheets': []}), 500

@app.route('/api/laws/articles', methods=['GET'])
def get_articles():
    """ì¡°í•­ ëª©ë¡ ì¡°íšŒ"""
    try:
        sheet_name = request.args.get('sheet_name')
        if not sheet_name:
            return jsonify({'error': 'sheet_name is required', 'articles': []}), 400

        articles = database.get_articles_by_sheet(sheet_name)
        app.logger.info(f'Retrieved {len(articles)} articles for sheet: {sheet_name}')
        return jsonify({'articles': articles})
    except Exception as e:
        app.logger.error(f'Error getting articles: {str(e)}')
        return jsonify({'error': str(e), 'articles': []}), 500

@app.route('/api/laws/paragraphs', methods=['GET'])
def get_paragraphs():
    """í•­ ëª©ë¡ ì¡°íšŒ"""
    try:
        sheet_name = request.args.get('sheet_name')
        article_num = request.args.get('article_num')

        if not sheet_name or not article_num:
            return jsonify({'error': 'sheet_name and article_num are required', 'paragraphs': []}), 400

        paragraphs = database.get_paragraphs_by_article(sheet_name, article_num)
        app.logger.info(f'Retrieved {len(paragraphs)} paragraphs for {sheet_name} - {article_num}')
        return jsonify({'paragraphs': paragraphs})
    except Exception as e:
        app.logger.error(f'Error getting paragraphs: {str(e)}')
        return jsonify({'error': str(e), 'paragraphs': []}), 500

@app.route('/api/new-session', methods=['POST'])
def new_session():
    """Create a new chat session"""
    session_id = str(uuid.uuid4())
    chat_sessions[session_id] = {
        'messages': [],
        'created_at': datetime.now()
    }
    app.logger.info(f'New session created: {session_id} from IP: {request.remote_addr}')
    return jsonify({'session_id': session_id})

@app.route('/api/chat/confirm', methods=['POST'])
def chat_confirm():
    """
    1ë‹¨ê³„: ì§ˆë¬¸ ìš”ì•½ ë° í™•ì¸
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ì´í•´í•˜ê³  í™•ì¸ ë©”ì‹œì§€ë§Œ ìƒì„± (FAQ RAG í˜¸ì¶œ X)
    """
    try:
        data = request.get_json()
        user_message = data.get('message', '')
        session_id = data.get('session_id', str(uuid.uuid4()))

        app.logger.info(f'[CONFIRM] Question from session {session_id}: {user_message[:100]}...')

        # ì§ˆë¬¸ ìš”ì•½/í™•ì¸ í”„ë¡¬í”„íŠ¸
        confirmation_prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì„ ì´í•´í•˜ê³  ê°„ë‹¨íˆ ìš”ì•½í•˜ì—¬ ë˜ë¬¼ì–´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: {user_message}

ë‹µë³€ í˜•ì‹:
"[ìš”ì•½ëœ ë‚´ìš©]ì— ëŒ€í•´ ë¬¸ì˜í•˜ì‹œëŠ” ê²ƒì´ ë§ë‚˜ìš”?"

ì˜ˆì‹œ:
- ì§ˆë¬¸: "ì‚¬ì—…ë¹„ êµë¶€ëŠ” ì–´ë–»ê²Œ ë°›ë‚˜ìš”?"
  â†’ "ì‚¬ì—…ë¹„ êµë¶€ ì ˆì°¨ì— ëŒ€í•´ ë¬¸ì˜í•˜ì‹œëŠ” ê²ƒì´ ë§ë‚˜ìš”?"
- ì§ˆë¬¸: "ì¸ê±´ë¹„ ê³„ì‚° ë°©ë²• ì•Œë ¤ì¤˜"
  â†’ "ì¸ê±´ë¹„ ì‚°ì • ë°©ë²•ì— ëŒ€í•´ ë¬¸ì˜í•˜ì‹œëŠ” ê²ƒì´ ë§ë‚˜ìš”?"
- ì§ˆë¬¸: "í˜‘ì•½ ì²´ê²° ì‹œ í•„ìš”í•œ ì„œë¥˜ëŠ”?"
  â†’ "í˜‘ì•½ ì²´ê²° ì‹œ í•„ìš”í•œ ì„œë¥˜ì— ëŒ€í•´ ë¬¸ì˜í•˜ì‹œëŠ” ê²ƒì´ ë§ë‚˜ìš”?"

ê°„ê²°í•˜ê³  ì •ì¤‘í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."""

        start_time = datetime.now()
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{'role': 'user', 'content': confirmation_prompt}],
            temperature=0.3,
            max_tokens=100
        )

        elapsed_time = (datetime.now() - start_time).total_seconds()
        confirmation_message = response.choices[0].message.content

        app.logger.info(f'[CONFIRM] Generated confirmation in {elapsed_time:.2f}s: {confirmation_message}')
        api_logger.info(f'Confirmation generated - Tokens: {response.usage.total_tokens}')

        return jsonify({
            'success': True,
            'message': confirmation_message,
            'session_id': session_id,
            'requires_confirmation': True
        })

    except Exception as e:
        app.logger.error(f'Error in confirmation: {str(e)}')
        app.logger.error(traceback.format_exc())
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

if __name__ == '__main__':
    app.logger.info('='*50)
    app.logger.info('Starting Civil Complaint Chatbot Application')
    app.logger.info(f'Debug Mode: {app.debug}')
    app.logger.info(f'Log files location: logs/')
    app.logger.info('='*50)

    # í„°ë¯¸ë„ì— ëª…í™•í•˜ê²Œ URL ì¶œë ¥
    print('\n' + '='*60)
    print('Civil Complaint Chatbot Server Started!')
    print('='*60)
    print(f'Local:   http://localhost:5000')
    print(f'Network: http://127.0.0.1:5000')
    print('='*60)
    print('Press CTRL+C to quit\n')

    app.run(debug=True, port=5000, host='127.0.0.1')